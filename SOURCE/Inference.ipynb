{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install mediapipe"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (0.8.3.1)\n",
      "Requirement already satisfied: six in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (from mediapipe) (1.15.0)\n",
      "Requirement already satisfied: opencv-python in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (from mediapipe) (4.5.1.48)\n",
      "Requirement already satisfied: dataclasses in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (from mediapipe) (0.6)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (from mediapipe) (1.19.2)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (from mediapipe) (20.3.0)\n",
      "Requirement already satisfied: wheel in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (from mediapipe) (0.36.2)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (from mediapipe) (3.15.7)\n",
      "Requirement already satisfied: absl-py in c:\\anaconda\\envs\\updatedpytorch\\lib\\site-packages (from mediapipe) (0.12.0)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from __future__ import absolute_import\r\n",
    "from __future__ import division\r\n",
    "from __future__ import print_function\r\n",
    "from __future__ import unicode_literals\r\n",
    "\r\n",
    "import scipy.io as sio\r\n",
    "import time\r\n",
    "import argparse\r\n",
    "import os.path as osp\r\n",
    "import torch\r\n",
    "from tqdm.notebook import tqdm as tqdm\r\n",
    "from IPython.display import HTML, Audio, display, Javascript, Image\r\n",
    "from base64 import b64decode, b64encode\r\n",
    "import numpy as np\r\n",
    "import html\r\n",
    "import time\r\n",
    "import io\r\n",
    "import PIL\r\n",
    "from PIL import Image\r\n",
    "import cv2\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from torch import nn as nn\r\n",
    "import os\r\n",
    "import mediapipe as mp"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "class handDetector():\r\n",
    "    def __init__(self, mode=True, maxHands=2, detectionCon=0.5, trackCon=0.5):\r\n",
    "        self.mode = mode\r\n",
    "        self.maxHands = maxHands\r\n",
    "        self.detectionCon = detectionCon\r\n",
    "        self.trackCon = trackCon\r\n",
    "\r\n",
    "        self.mpHands = mp.solutions.hands\r\n",
    "        self.hands = self.mpHands.Hands(self.mode, self.maxHands,\r\n",
    "                                        self.detectionCon, self.trackCon)\r\n",
    "        self.mpDraw = mp.solutions.drawing_utils\r\n",
    "\r\n",
    "    def find_hands(self, img, draw=True):\r\n",
    "        imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\r\n",
    "        self.results = self.hands.process(imgRGB)\r\n",
    "\r\n",
    "        if self.results.multi_hand_landmarks:\r\n",
    "            for handLms in self.results.multi_hand_landmarks:\r\n",
    "                if draw:\r\n",
    "                    self.mpDraw.draw_landmarks(img, handLms, self.mpHands.HAND_CONNECTIONS)\r\n",
    "        return img\r\n",
    "    \r\n",
    "    def get_num(self, num):\r\n",
    "        temp = num.split(\".\")\r\n",
    "        num = temp[0] + \".\" + temp[1][:3]\r\n",
    "        return num\r\n",
    "    \r\n",
    "    def find_pos(self, img, hand_num=0, draw=False):\r\n",
    "        global count\r\n",
    "        global prev_angels\r\n",
    "        global prev_xz_angels\r\n",
    "        \r\n",
    "        lmList = []\r\n",
    "        angle = 0\r\n",
    "        xz_angle = 0\r\n",
    "        \r\n",
    "        if self.results.multi_hand_landmarks:\r\n",
    "            my_hand = self.results.multi_hand_landmarks[hand_num]\r\n",
    "\r\n",
    "            id_5 = [0, 0, 0]\r\n",
    "            id_17 = [0, 0, 0]\r\n",
    "            \r\n",
    "            for id, lm in enumerate(my_hand.landmark):\r\n",
    "                if id == 5:\r\n",
    "                    id_5[0] = lm.x\r\n",
    "                    id_5[1] = lm.y\r\n",
    "                    id_5[2] = lm.z\r\n",
    "\r\n",
    "                if id == 17:\r\n",
    "                    id_17[0] = lm.x\r\n",
    "                    id_17[1] = lm.y\r\n",
    "                    id_17[2] = lm.z\r\n",
    "\r\n",
    "                h, w, c = img.shape\r\n",
    "                cx, cy = int(lm.x * w), int(lm.y * h)\r\n",
    "                lmList.append([id, cx, cy])\r\n",
    "                if draw:\r\n",
    "                    cv2.circle(img, (cx, cy), 5, (255, 0, 255), cv2.FILLED)\r\n",
    "\r\n",
    "\r\n",
    "            difference = np.array(id_5) - np.array(id_17)\r\n",
    "            angle = np.arctan2(difference[0],difference[2]) + np.pi\r\n",
    "\r\n",
    "            zplane = np.array([0,1,0]).astype(np.float)\r\n",
    "            vec_normed = np.linalg.norm(difference)\r\n",
    "            zplane_normed = np.linalg.norm(zplane)\r\n",
    "\r\n",
    "            result = (difference*zplane)/(vec_normed*zplane_normed)\r\n",
    "            xz_angle = np.arcsin(np.sum(result))\r\n",
    "            \r\n",
    "            xz_angle = (1-np.abs((xz_angle/ np.pi) * (2)))\r\n",
    "\r\n",
    "            avg_angles = angle\r\n",
    "            avg_prev_xz_angels = xz_angle\r\n",
    "\r\n",
    "            if draw:\r\n",
    "              x = int(np.cos(avg_angles)* avg_prev_xz_angels*512) + 128\r\n",
    "              y = int(np.sin(avg_angles)* avg_prev_xz_angels*512) + 128\r\n",
    "              \r\n",
    "              cv2.circle(img, (x,y), 5,(255, 0, 0), cv2.FILLED)\r\n",
    "              cv2.line(img, (128,128),(x,y),(255,255,0),2)\r\n",
    "              \r\n",
    "              cv2.putText(img, f'xz_angels {str(avg_prev_xz_angels)}', (2, 30), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\r\n",
    "              cv2.putText(img, f'angles {avg_angles}', (2, 50), cv2.FONT_HERSHEY_PLAIN, 1, (0, 0, 255), 2)\r\n",
    "            \r\n",
    "        else:\r\n",
    "            return None, None\r\n",
    "        return avg_angles, avg_prev_xz_angels "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def compute_zplane_angle(posmat, joints=(17,5), radians=True):\r\n",
    "  vec = posmat[:,joints[0]] - posmat[:,joints[1]].type(torch.float)\r\n",
    "  zplane = torch.tensor([0,1,0]).type(torch.float)\r\n",
    "\r\n",
    "  vec_normed = vec.norm()\r\n",
    "  zplane_normed = zplane.norm()\r\n",
    "\r\n",
    "  result = (vec*zplane)/(vec_normed*zplane_normed)\r\n",
    "  angle = torch.asin(torch.sum(result))\r\n",
    "\r\n",
    "  if radians:\r\n",
    "    return angle\r\n",
    "\r\n",
    "  return (angle/torch.pi)*180\r\n",
    "\r\n",
    "\r\n",
    "def compute_x_z_angle(posmat, joints=(17,5), radians=True):\r\n",
    "  vec = posmat[:,joints[0]] - posmat[:,joints[1]]\r\n",
    "  vec = vec.squeeze()\r\n",
    "  angle = torch.atan2(vec[0],vec[2])\r\n",
    "\r\n",
    "  if radians:\r\n",
    "    return angle\r\n",
    "\r\n",
    "  return (angle/torch.pi)*180"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class PoseToVecModel(torch.nn.Module):\r\n",
    "    def __init__(self, inputSize=2, outputSize=2, depth=0, width=8):\r\n",
    "        super(PoseToVecModel, self).__init__()\r\n",
    "        mlist = [nn.Linear(inputSize, width)]\r\n",
    "        rlist = [torch.nn.PReLU()]\r\n",
    "        for i in range(depth):\r\n",
    "          mlist.append(nn.Linear(width, width))\r\n",
    "          rlist.append(torch.nn.PReLU())\r\n",
    "\r\n",
    "        self.last = nn.Linear(width, outputSize)\r\n",
    "\r\n",
    "        self.linear = torch.nn.ModuleList(mlist)\r\n",
    "        self.rels = torch.nn.ModuleList(rlist)\r\n",
    "\r\n",
    "    def forward(self, x):\r\n",
    "      for i in range(len(self.linear)):\r\n",
    "        x = self.linear[i](x)\r\n",
    "        \r\n",
    "        x = self.rels[i](x)\r\n",
    "        \r\n",
    "      x = self.last(x)\r\n",
    "\r\n",
    "      return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "model_checkpoint_path = \"/Documents/Afeka/Handy Project/Midterm Report/21.03.21/checkpoint_6000_gtloss_1.0657_shouldbegood_new_model.pth\" \r\n",
    "model = torch.load(model_checkpoint_path)\r\n",
    "model.eval()\r\n",
    "\r\n",
    "detector = handDetector()\r\n",
    "cap = cv2.VideoCapture(1)\r\n",
    "\r\n",
    "prev_angles = [0, 0, 0, 0, 0]\r\n",
    "prev_xz_angels = [0, 0, 0, 0, 0]\r\n",
    "count = 0\r\n",
    "\r\n",
    "\r\n",
    "while True:\r\n",
    "    success, img = cap.read()\r\n",
    "\r\n",
    "    with torch.no_grad():\r\n",
    "        \r\n",
    "        detector.find_hands(img, draw=True)\r\n",
    "        angle, xz_angle = detector.find_pos(img, draw=False)\r\n",
    "\r\n",
    "        if angle is not None:\r\n",
    "            input = torch.tensor([angle, xz_angle]).type(torch.float32)\r\n",
    "            angle, xz_angle = model(input)\r\n",
    "            \r\n",
    "            count += 1\r\n",
    "            prev_angles[count%4] = angle\r\n",
    "            prev_xz_angels[count%4] = xz_angle\r\n",
    "\r\n",
    "            avg_angle = sum(prev_angles)/len(prev_angles)\r\n",
    "            avg_xz_angels = sum(prev_xz_angels)/len(prev_xz_angels)\r\n",
    "            \r\n",
    "            y = int(np.cos(avg_angle)* avg_xz_angels*128) + 128\r\n",
    "            x = int(np.sin(avg_angle)* avg_xz_angels*128) + 128\r\n",
    "\r\n",
    "            cv2.circle(img, (x,y), 5,(255, 0, 0), cv2.FILLED)\r\n",
    "            cv2.line(img, (128,128),(x,y),(255,255,0),2)\r\n",
    "\r\n",
    "    cv2.imshow(\"Image\", img)\r\n",
    "    \r\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\r\n",
    "        break\r\n",
    "        \r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}